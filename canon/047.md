

0:02 / 0:40


Toby St Clere Smithe: "Compositional Active Inference"

Topos Institute
11.6K subscribers

Subscribe

34


Share

Save

1,124 views  May 16, 2021  Finding the Right Abstractions
Finding the Right Abstractions Summit

Slides: https://tsmithe.net/papers/20210512-f...
Chapters

View all
Featured playlist

18 videos
Finding the Right Abstractions
Topos Institute
Transcript
Follow along using the transcript.


Show transcript

Topos Institute
11.6K subscribers
Videos
About
2 Comments
Default profile photo
Add a comment...

@DumblyDorr
3 years ago
This is extremely fascinating - and basically exactly what I wish to explore further as a program in structuralist philosophy of science (specifically meta-theory of natural sciences). Basically a continuation and expansion of the set-theoretical and model-theoretical approaches of the Munich structuralists (Sneed, Balzer, Moulines et al) - who (not coincidentally) already hinted at the promising nature of category-theory. Now, with various kinds of (modal) Homotopy Type Theory, including cubical type theory - the time seems to be ripe, and this talk expresses exactly the kind of reason I believe can advance and maybe fulfill the idea of successful structuralist accounts in meta-theory of natural sciences. Bravo!

Having only received an MPhil in philosophy of science and formal logic so far, I am currently back at university to study for a math-degree in order to work not just with the general concepts, but the nitty-gritty details. It will be a while before I have the time to pursue these research-interests in any depth again - but I'm looking forward to the inspiration and advances to be found in the talks at the Topos Institute in the meantime - and maybe join you once I'm done with my second degree :)

I can honestly not thank the Topos Institute, its organizers and wonderful speakers enough - it is deeply appreciated that you publish these talks here for everyone to see. It seems these ideas have finally "got the ball rolling", and productive, interdisciplinary research related to all things structuralism is happening more and more. I'm very glad to see it.
7
Reply

@toonvanhauwermeiren4013
6 months ago (edited)
Around 29:00, where you explain the composition of Bayesian lenses, the rewiring of the diagram appears to assume that c followed by copy of Y is the same as copy of X followed by c applied to each of the copies. I thought you can do that only in a cartesian category, not in a Markov category.
Reply
Transcript


Intro
0:04
right so i'm going to be talking about uh what i think of as a compositional
0:10
theory or account of what's known as active inference and i believe along with a number of
0:16
people that active inference encapsulates the process by which things like intelligence systems learn
0:24
about their world and effectively learn to survive in their world and of course that means
0:29
they need to learn explanations of the things that they encounter in their world
0:34
and i think of those kinds of explanations effectively as right abstraction it's a good explanation it's something that allows
0:41
you to summarize your incoming data which is much like an abstraction it seems to be
0:47
so first of all i'll give a bit of background my background personally is in computational neuroscience although i've had some formal training
Some Background
0:54
i'm a default student in the psychology department at oxford um i've gone up quite row by doing so
0:59
much category theory lately um and the reason that i did that was that i was dissatisfied with
1:04
the mathematical structure of computational neuroscience more generally so i i wanted answers to
1:11
questions like how do models relate to each other how do they plug together and how do we understand that
1:17
resulting model how do we translate ideas and concepts between different research groups how can we stop
1:24
reinventing the same concepts all but yeah over and over again and i realized
1:29
after not much investigation that i was seeking effectively a compositional lingua franca
1:35
something sufficient to express common patterns translate ideas and connect things together and of course something like
1:42
category theory in fact so today i'm going to tell you some of the things that i've learned about
1:48
what i think of as the structure of learning structure i'm going to emphasize compositionality
1:55
and that really means taking interaction very seriously and so i'm going to sketch the
2:01
beginnings of a news story and think feels like computational
2:06
neuroscience especially a kind of cybernetic story to answer questions like how do adaptive
2:11
systems find abstractions how do things learn anything how are the
2:17
resulting beliefs structured and do we ever have more than consensus
2:23
at topos we're institute we're interested in telling such kinds of news stories for all kinds
2:30
of systems interconnected systems particularly and so we seek a new interconnected scientific ontology
2:37
and i'm sure that that's going to be really important in human flourishing things like ai
2:43
alignment um i'm with valeria on this i think we need to seek
2:48
ai alignment for the artificial intelligence is that we already have things like corporations and social
2:54
systems and we should be concentrating on those right now and i think i and the rest of the
3:02
topples institute hopes that acknowledging interaction should promote
3:07
sustainability of human society on earth okay so we're going to start with a kind
Overview
3:14
of review of the familiar stuff what makes the world compositional
3:19
in particular i'm interested in spaces and the things that are living in those spaces and what to make
3:24
what makes them living things so of course the world is really complicated and
Compositionality at Large (3/3)
3:31
so are things within it but at the same time it does seem to be more often than not
3:36
made of things plugged into other things connected together and so it seems that if we are to have
3:43
any hope at all of understanding the complexity of the world and the complex systems that we've built in it
3:50
we might as well make use of this latent structure which we seem to observe and i think that's what the brain does
3:55
all the time by observing patterns and effectively isn't making use of
4:02
latent structure what right abstractions are all about
4:08
so we know this quite well i suppose that categorical or more broadly compositional structures are everywhere
4:15
maps of the world dynamical systems topological spaces logical statements neural circuits
4:21
natural language statements i don't need to list the rest of them they're all over the place i think it'd be really interesting to
4:27
find something that was a kind of interesting system a phenomenon which didn't have some compositionality to it
4:33
and in particular the kinds of systems that we're often interested in in studying compositionality
4:39
are things that we could think of as open system because they have a kind of obvious way of being
4:45
plugged together but even things that might not look open could be
4:50
divided up and so it might admit some kind of compositional description
4:56
so i'm sure that taking connectedness and compositionality seriously means really acknowledging
5:01
two related things that systems interact and that therefore their behaviors are
5:07
context dependent and we have to take this context bit seriously too
5:13
because only tautologies are true if you don't make any assumptions if you don't have a context
5:21
now i'm sure most of you know that the fundamental theorem of category theory yaneda's says that roughly
5:28
speaking the way that the thing connects to others and itself determines the thing itself
5:35
and this comes up everywhere there's the maxim of the linguist who says you shall
5:40
know a word and this applies equally to places or concepts by the company of keats and that applies
5:46
to to our abstractions our models and the stories they tell
5:52
so i want to tell a particular story about things living things in the world in the
Compositional Spaces
5:58
space that is the world the space the stage on which events occur space itself is
6:06
compositional because we can glue bits of spaces together for instance think of building an apartment block
6:12
you're kind of gluing floors one on top of another or more more abstractly here on the right we've
6:17
got a picture of a symphysial complex and that's a kind of cellular space made by gluing smaller
6:24
more simple cells together but spaces are kind of more than just
Categorified Spaces
6:30
the collections of points glued together there are also paths between the points
6:37
and i've drawn a kind of space here with some paths between them and so we can think of spaces in a kind of
6:43
categorical language categorifying them accordingly paths in the space become morphisms
6:50
the morphisms tell you how to get from one place to another and sometimes you can go and you know
6:56
both directions long power sometimes it's directed but the key idea is that parts are like like morphisms rather are
7:02
like parts in some space and this points the way to
7:09
what is called toppos theory toppos is kind of like a nice categorification of a space with some
7:15
kind of nice logic that i'll talk about momentarily
7:20
so there are various notions of topos the kind of that i'm talking about is
Topoi as Spaces
7:25
formerly called a britain deep topos that i think you should think of roughly speaking any kind of
7:31
thing that's called a topos as a kind of categorified space um and we can sometimes divide these
7:37
topoi into two kinds big and small and in a big topos we can
7:43
think of the points the objects of the topos themselves as spaces and the paths in the topos the maps
7:51
are kind of maps between spaces so if you think of like this picture on the left as being
7:56
some diagram in a top post you can kind of zoom in on these objects which are themselves spaces and
8:02
draw what the maps mean that's these kind of like gray lines on the right yeah and think you know
8:10
when i'm moving around this space i'm mapping points and spaces to other points okay well that's a nice story so what
Bundles and Dependent Types
8:18
can we do with this well we'll see later on something that we can do with this um but first of all we need a bit
8:23
more theory so i want to talk a bit about slice categories so the slice
8:31
over an object in a category let's think of the middle object on the left this space
8:37
with this three dots in it so the slice over this x is the category of objects that map
8:42
to x and this in topos theory gives you another topos and it's the
8:49
topos in the context of x its objects are what are called bundles like this picture on the right
8:57
this is one this is kind of version of this map on the left on the left here
9:03
and a bundle represents something called a dependent type and it says that for each point in
9:09
the codomain we get a collection of points in the domain of the map which is given
9:15
by pulling back where the map takes you to so for instance with this point on the left it gives you this set of points
9:22
there's two points on the left here and these things they we can think of them as like abstract
9:29
dependent types types with a context we can think of things like we think of the base this this of the
9:37
co-domain object which we call the base of the bundle or the base of the dependent type
9:43
as like a place and the types above it where we pull back these points too
9:50
they say things like they're the stuff that can happen in each place so an example i like to use
9:56
to think about dependent types and bundles is like a weather forecast
10:01
the kind of weather forecast you get depends on where you are on the earth for instance if you're on
10:08
land you might care about things simple things like whether the sun is shining or whether it's raining
10:14
or the temperature but if you're oversea you're probably on a boat and you might care a bit more about things like the tides or
10:21
more information about the wind pattern and so this type the weather forecast
10:28
type depends on where you are in the space that's what makes it a dependent type but more generally speaking any
10:35
sheath for instance like david jazz was talking about before gives you a kind of dependent type we
10:41
can think of dependent types in the same way as attaching data onto points of the space here you're attaching these data spaces
10:48
to the points of this base space and what uh another thing that we'll come
10:53
across and that david has talked about polynomial functors they're also a kind of
10:58
bundle so it's good to sort of get that theory down because we're going to be talking about them a bit now
11:05
um but before i do so i want to talk a bit about what's known as the internal language
Logic and Dependence
11:11
what you can say if you just stay in the world of the topos so the internal language is like a kind
11:18
of logical language you can write down propositions about
11:23
the objects in morphism or the types as it were in the topos and this logic is higher
11:29
order you have conjunctions and disjunctions and implications and quantifiers that say things like there
11:36
exists an x such that why or that for all x
11:41
each topos has a special object called a sub-object classifier and this assigns truth values to propositions and
11:48
these two truth values in a spatial topos are kind of like roughly that they're saying something like where a
11:54
proposition is through for instance if you have the proposition it's sunny you know that's only true in the places
12:01
that it is actually sunny and so the truth value true or false varies as you move around the base space
12:09
and in the topos of course as i mentioned we can construct dependent types in this internal language um
12:17
the base of each bundle gives us a logical context we can think of this as saying something
12:24
about the axioms we impose this is what i was referring to earlier
12:29
the assumptions you make about the structure of the space so what bits are connected to what other
12:35
bits for instance which land masses in the weather forecast example are connected to which others
12:42
and so changing our assumptions or the context corresponds to moving
12:49
around the base space or changing the base topos for instance as kind of tectonic plates
12:57
move around on the surface of the air okay so that's a bit of logic and a bit
13:04
of i don't have time to go into norfolk to
13:09
talk about i want to get onto living things and their internal models i think some great examples of things come from biology
13:16
we're too familiar it seems with kind of artificial things which are simple and often not interconnected but
13:21
biology is full of really interconnected examples so we've got you know cells obviously that are really
13:27
like thingy and connected to other things around them their behavior depends on what's around but more you know kind of
13:34
lower level we have enzymes and proteins which have great shapes and that interacts by sort of
13:40
plugging together in the same kind of way that computer networks plug together it seems
13:46
but these change their shapes um and of course we've got things like
13:51
neurons and they form the neural circuits that i started with and you know we want to you know we want
13:58
to talk about how these things are connected and so we're going to try and put some sort of formal compositional language
14:03
onto that and so i'm going to adopt um polynomial functors for this and this is thanks to david spivak
Polynomials for Interconnection
14:11
um okay so i'm going to start with these things which are basically like wiring diagrams to
14:17
describe how things are connected up and you can read these from left to right and you can think of that as going from
14:23
something like input into output and i'm going to use this funny notation this kind of polynomial notation at the bottom to
14:29
describe the boxes and the wiring of the boxes to other boxes
14:34
so this box on the left is a box from z inputs to c output so i'm going to write
14:40
that as c times y to the z and we can make this a bit more complicated here's one that has
14:46
outputs in bz and inputs in yc and now
14:52
the morphisms of polynomials are going to be ways of wiring things together so here we've got two systems
14:58
this uh the two systems i've drawn on the left and we put them in a box next to each other and putting things next to
15:04
each other corresponds to doing this kind of minority product this tensor product thing here and that is a we're not a
15:09
product structure on the calculator and wiring these two boxes together around to this outer box is a morphism
15:16
polynomial but now it doesn't matter precisely so you're saying so i'm just
15:23
looking formally at this right so the tensor is actually um
15:30
like wiring up the z of the one with the z of the other is that right
15:35
the tensor is just putting things together it just puts it just puts the bz and the c next to each other
15:40
in the coefficients and the z and the y c next to each other this is like doing products in the coefficients
15:46
and the exponents and then the wiring is what's done by this polynomial map um
15:57
is this supposed to suggest something uh uh yes it you it's both supposed to suggest
16:03
um the exponential structure in a category
16:09
where we can well we write the set of maps from z to c as the exponent c to the z
16:17
um and it's formally the case that this y is like representing the this kind of
16:24
representable function the function of maps from zed uh rather from uh to something else
16:31
it's a copri chief and so formally they work out in this kind of same exponential way um but for now we can
16:38
just think of these things as like notation but yeah okay okay but i'm trying to understand the notation so
16:43
i um i tensor them so i just put them parallel next to each other they're not connected
16:50
and now you're saying this map that you there's some sort of map to byy
16:56
and this is gonna this is gonna wire them up or like what is the wiring information
17:02
where is that wiring information is encoded in the morphem of polynomials which says how you take the
17:09
outputs and the to outputs of the outer box and how you take the inputs to the
17:14
inputs of the inner boxes and at the same time it effectively says where the inner boxes get their
17:20
information from but i find this weird because if i have it i suppose you can have multiple z
17:28
inputs or something right how do you know that this c has to
17:33
like wire up with with with that specific z as opposed to just all the exponents are
17:39
indexed by position in the base by by effectively a coefficient so this is like the thing on the left here the c
17:46
y to the z is like c times y to the z so it's like y to the z plus y z plus y equals z c
17:52
times and so for each point in c you get a z okay and so that gives you an indexing
17:58
thank you okay um so this is i mean this is just a this is just a i mean it's good to it's
18:04
good to get this sorted but it's just uh it's just like a little example for now we're gonna we're gonna get a bit more
18:10
complicated but we don't need to talk about all the details i'm just trying to tell a story and if we want to do the kind of
18:16
formal stuff we can talk about that later on and in particular this stuff can get much more sophisticated
18:22
and these polynomials can talk about things like the shapes that can change but for now i want to talk about how we
18:28
know what stuff is out there how do we even start to talk about finding the right abstractions
18:35
okay and so for this we're going to talk about models and statistical models and how they are
18:40
updated um i like this idea of elon vitale what is
Whence the elan vitale?
18:46
the the animating spirit or force that gives things in the world life how do we talk
18:52
about that formally um and so more precisely i mean
18:57
what is the structure of an agent or a things internal model you look at a thing and
19:03
you know inside of it somehow maybe it has a way of predicting the world and what is its structure and what makes
19:10
that kind of that structure possibly modular like we think maybe the brain or mind seems to be modular how do the models that we have of
19:18
kind of the in these systems how does that relate to their forms and their interconnection okay
19:25
and so for this we need a bit of categorical probability theory i don't want to spend an awful lot of
Introducing Markov Categories
19:30
time on this um because again i'm just trying to tell a story but i think it's important to get the terms that i'm
19:36
using clear so i'm going to be working in what's known generally as a markov category which is basically like an
19:42
abstract place that you can do probability theory in this case the objects of the category
19:47
are going to be spaces the morphisms are going to be what i call stochastic channels
19:53
and we can think of these as conditional probability distributions they say given a point in x i get a distribution
19:59
of y and so that's saying okay given some x observation what is my y belief or my yeah
20:07
my condition my probability of events in y conditioned on obviously observing x
20:12
they're the same thing uh there are these things called states which are just going to be distributions
20:17
on a space and those are channels out of the minority unit which is typically going to be the kind of trivial space with one
20:24
point um and although i'm not going to write much probability notation
20:29
um i'm going to adopt this kind of standard notation where if i have a channel from x to y
20:38
like this i'm going to write the probability assigned to point y given x as p of y given x even though really
20:45
formally it's a function applied like p of x of y okay and then you can compose these
20:51
things and this composition of these uh conditional probability distribution of these stochastic channels is given by
20:57
averaging over the type in the middle of the composition and sort of marginalize in out we can
21:04
think of that as kind of pushing forward uncertainty along these channels okay i'm going to draw some diagrams not
21:12
many diagrams but i do want to talk a bit about bayesian inversion and joint probability distributions and
Joint states and generative models
21:19
what people call generated models and for that i find these diagrams quite intuitive and helpful
21:24
and so i want to talk a little bit about those first we can draw these things with kind of multiple wires coming out
21:30
and they serve two purposes one they start to describe the kind of causal structure
21:37
of something like a generative model because we can think of the information that's flowing from the bottom up through the model but they also
21:44
describe how the model factorizes and so we can you know we know we can decompose some joints
21:50
joint distribution into a prior and a likelihood on its margin like you know likelihood on one of its
21:56
um marginal spaces and we can draw this kind of this kind of product rule like this
22:03
yes so okay i think i understand x y you know the wire next to each other
22:08
that's the tensor of two objects yeah and so it's like a joint space yeah
22:13
exactly x tensor y right that's that's what this thing but then the triangle what is what is
22:18
that the triangle is just it's just a notation that says there's a trivial space here
22:24
and so it picks out a distribution on some space because a map from a trivial space into
22:31
some other space is just an element of that space in this case the the space is distributions on x
22:37
and so this is just a distribution on x and we can think of that as the prior of this model here or the or the
22:44
equivalent of the x marginal so no but i'm sorry still confused like
22:49
i have x tensor y and i'm mapping to d of one or something is that is that
22:55
where d is d is the the the closely you know the
23:00
the set of probability distributions no no we're reading from the bottom up oh ah okay so oh i'm going
23:08
from i to x tensor y is that yeah so it takes out a joint state right so that is
23:15
like a distribution on x times y and that joint state is factored because of this like probability of this like
23:22
uh product rule and probability that says you can factor joint state into a prior and a likelihood right
23:30
so uh what is the the dot like category oh this is just multiplying numbers i
23:36
this is me saying i don't like the way people write probabilities and so i'm going to write it in diagrams
23:43
but you know the dark dot oh the dark dot is okay so it's a it's a copier in the category it's like a
23:49
the the the canonical morphism from the comonode
23:55
structure the comodo okay which is x okay
24:00
and this is just saying this this joint distribution factors like this it's just notation but i also like to
24:06
think of it as describing the information flow but i want to make progress i need to make progress okay
24:11
um so you know okay so we've got marginals we can throw away and we get that by throwing away one of
24:17
the wires on the we can throw away the right wire to get the margin on the left which is just pi and we can throw away
24:23
the left wire to get the module on the right on y which is uh c
24:29
after pi which is you know this thing which we normally write down as you know sum over
24:36
all the x's uh c of x cube and y times pi over x i mean
24:42
that's what this thing says here that's the other margin okay we can write down bayes rule it's a
24:49
way of kind of translating between two different uh represent decompositions
Bayes' rule, categorically
24:56
disintegrations or a product uh distribution it says that i can go
25:01
from a channel from x to y the conditional probability from x to y to a channel from
25:07
white x that says given some y observation what should my prior belief have been or how should i
25:12
update it and it satisfies this this rule which is again just another version of the pro
25:18
product rule in probability theory it has this nice graphical form it has this nice kind of um
25:26
symmetry sorry is saying that this bass rule endows the mark of category with
25:32
some sort of dagger structure it does in a sense it endows the slice under the
25:40
terminal object with a dagger um oh yes okay but the key point i want to make is that
25:46
it's not it's not just a dagger on the category itself because it depends on the prior right you don't
25:52
get a channel unless you know what your prior was you need to choose a prior
25:57
in order to find an inverse channel but it's actually on the undercat or the co-slice category it's
26:03
the it's a diagram the co-slice category but i'm just using the dagger notation okay yeah but and that co-size category
26:10
says that that fact says that we need a prior and that's the key point that i want to make now
26:16
uh given a generative channel that says given some prior belief i make observation why
The bidirectionality of Bayesian inference
26:22
are the recognition channel that goes in opposite direction depends on the prion has this type as a
26:28
prior on x times observation in y gives me a new belief on x and so we compare these
26:36
forwards channels that make predictions with these update maps with these kind of dependent update maps
26:42
that pairing is called a lens they're all over the place they encapsulate what david jazz is calling
26:47
hierarchical planners and we can prove and i'm not going to prove it now
26:52
they can look it up that the inverse of a composite channel that says okay so say if say you're like at the cinema you're
26:59
trying to predict the cinema screen you can only look a little patch of the screen then you make a prediction about
27:04
you know the whole image given predictions of the patches you've got a composite channel that does that
27:11
and you can update your belief about the whole image say this kind of latent belief by first
27:17
updating your belief about the patch which is the thing you're looking at and then using that updated information to update your belief about
27:23
the whole picture and that might be how the brain does updating complicated scenes and it's quite nice because this is
27:29
in some sense the right abstraction because this compositionality property seems to match
27:35
up nicely with the kind of um compositional structure that we see in the cortex where we've got these kind
27:42
of local circuits which do sort of up based in updating of uh kind of component channels but i'm
27:49
not talking about that today i'm only saying that we can do phase and inference in a nice compositional way
27:54
and then it has this structure um i'm not going to walk us through these diagrams it's something that we
28:00
can come up to but each of these boxes is one of these lenses a pairing of a forwards and a backwards
28:05
channel and this just says that we can compose the forward channels and
28:11
backwards channels according to the lens composition rule um which says that
28:16
okay the composite of the joint of the of the inverse rather of the composite
28:22
channel is just given by the composite of the inversions according to this rule it
28:28
says first of all you inverse you invert d you have to use the information
28:33
predicted by c and then you can push that through the inversion of c so you kind of go in the
28:39
opposite direction which is kind of what you'd expect because you're going you're sort of going making predictions from causes out into
28:46
observations and then you have to go back from observations up to courses and so it has this kind of factor structure okay these are the things that
28:54
i'm going to call bayesian lenses and they formalize what i like to think of as hierarchical
29:00
like predictive models um but the structures i was talking about
29:06
just then are kind of exact inversions and obviously yes could you say what you mean exactly
29:12
by beijing lens what is the definition a bayesian lens is a pair of a forward
Bayesian lenses
29:18
channel or condition probability distribution and one of these backwards channels which takes in a prior and gives you
29:24
the updated prior and given a given observation okay so so that there's the forward
29:31
channel from x to d y is that right yeah so it's like an index it's like a family of distributions on y
29:39
right yes yes and then you're saying so what is the price is that a prior is
29:44
that what you're saying oh no the prior is the thing that you supply to get the distribution on y so you get
29:51
say you've got a distribution on x that's what i would call the prior okay so i have a channel
29:57
so i have a distribution a prior on oh oh okay so i have like a a like i i have
30:04
like a whole param what i call w or earlier i have like a whole parameter space yeah
30:09
that is an x is the parameter space of distributions on y and then then i have a
30:18
prior on that so i distribution on that and then given a y a point in y
30:26
it updates all these uh this uh it it it yeah okay yeah
30:33
right that's right okay and this is what you call basic lens okay cool and then these form uh yeah candidates from the
30:39
category and they compose according to this lens composition rule right i'm not going to talk about because i'm just saying that it exists
30:45
and the rule is here but um i need to let's need to make some progress again because those are exact
30:51
lenses and you know systems in the real world typically can't do exact inversion
Statistical Games for Approximate Inference
30:57
because it's too computationally difficult we can do approximate inversion and so we want to talk about how
31:02
well a system does at this inversion right there's a lot of freedom in
31:08
choosing an inversion in approximation we could choose the trivial approximation that just picks
31:14
out the same distribution as the prior all the time and that would be really rubbish mostly it'd be right sometimes but
31:20
mostly rubbish so we want to quantify how fit or the fitness of an approximation scheme and
31:27
that depends on how the system interacts with the world it depends on two things
31:33
the prior and the environment that the system is in so the approximation is as i say context
31:39
dependent and parameterized well we can talk about the parameters later but i'm going to focus on the on the context so i'm going to make this
The Category of Statistical Games
31:46
category of what i call statistical games i call them games because you can think of the system as playing the game
31:52
trying to maximize its performance at making predictions about the world so the category is going to have
31:59
morphisms which are the same as the objects of the category of bayesian lenses so that's pairs of spaces
32:04
often it's just the same space twice anamorphism is going to be one of these bayesian
32:10
lenses equipped by a loss function which takes contexts which i'll define
32:16
in a moment into real numbers that say how good the system is at playing at doing the prediction
32:22
so these contexts are everything needed to make this lens which takes inputs and gives outputs
32:29
everything needed to make that open system a closed system and so that's going to be so we think of the closed systems as ones with trivial
32:35
inputs and outputs and so that means i'm going to have a lens from ones
32:41
and into the domain type and a lens from the codement type into ones and you'll just have to trust
32:46
me on this but that works out to mean a prior so a distribution on x for a
32:52
lens of this type and what's called a continuation so this says
32:57
given some predictions about why i make some observations in b and typically y is the same but it's
33:02
saying what does the what observations or what data does the environment give the system
33:11
okay and then we compose these things given using the lens composition rule and i i just say we just add up the
33:16
fitness functions i mean that doesn't matter okay so then we can we can formalize
33:22
lots of kind of like statistical tasks in this setting maximum likelihood estimation for instance
Example: Maximum Likelihood Estimation
33:27
corresponds to bayesian lenses with no inputs no priors and just a state because they're saying okay i make a
33:34
prediction about my i make a prediction about my data set and i'm trying to you know change the
33:39
parameters of this prediction of this this distribution i've got in my head in order to explain the data better
33:45
so i have just a state a distribution and i have some data which is just this thing given by the continuation
33:52
and i'm trying to say here's my loss function it's saying maximize my likelihood and we can think of this likelihood
33:59
function this log probability function as in the following way right so like we can think of this density
34:06
this t that's given by the pi state or state distribution that's
34:12
measuring the likelihood saying that high probability things you know are
34:17
likely that's just what probability means and so and what i will think of as an optimal strategy for this kind of
34:22
game is one that just maximizes likelihood in this context that says given
34:28
the state you know under the expectation induced by the data observed in the state given by
34:34
the k that's a maximum likelihood gain we can extend this to a bayesian
Example: Bayesian Inference
34:40
inference so we've got now like priors and we're making predictions given our prior beliefs
34:45
so what we're doing now is choosing a channel which gives us the best observations and also
34:53
can do the lens which gives us the best predictions and also can do the updating in a good way and so that
35:00
says given all my observations i want to minimize the average divergence from the exact
35:07
inversion given my approximation that's what this loss function
35:12
says okay and then since the bayesian updates compose according to this lens rule you can these games are
35:20
closed on under composition two so we get this kind of nice property that a composite approximate influence game
35:25
is like uh the approximation or a composite okay
35:30
but computing this divergence is difficult and so we can do things like uh various approximations to
Example: Free Energy Game
35:37
it yeah like this one called the free energy which is quite prominent and this is just an upper bound on this
35:44
divergence that ends up if you write out the equations to be easier to compute and it turns out in some situations that
35:50
if you write them right out the equations they look a bit like what neural circuits look like and so people think okay well that's
35:56
what the brain does this is a story we can tell another day i'm saying this is one way of doing this
36:03
approximate bayesian inversion the question i'm interested in today is how do we make systems that might be
36:09
equipped with this kind of model in some sense live how do they how do they then find abstractions how do they
36:15
act in the world notice i haven't talked about interacting systems at all just predictions sorry
36:21
toby yeah i'm running out of time i've gotta okay what are you what's the question
36:31
hello alexander i think he uh i think he ran off um okay
36:38
i mean how much time can i take yeah uh so toby you should consider yourself to be free to take
36:45
uh up to 15 more minutes if you need total okay that should be perfect
36:53
okay so um we can we can talk about the details we can talk about the details afterwards i want to get to the end of
36:58
my story um okay so so the next step okay i've got this idea
37:03
about statistical models that might be in the heads of all the brains of the systems how do they how do
37:10
we breathe life into those systems how do those systems find abstractions okay this is what i'm going to talk about now i'm going to go back to these
37:16
polynomials these boundaries of the systems okay so i drew this box
Polynomial Morphology (2/2)
37:21
before this pattern of interconnection and i said okay there are some
37:26
polynomials and morphemes and polynomials and that's the installation pattern but the thing is it's not just boxes and wiring
37:32
there's much more to this this kind of structure than that we can talk about all kinds of
37:38
uh interconnected systems and in particular we can talk about systems with some kind of shape that interacts with some other kind of
37:43
shape by kind of coupling together like the enzyme protein complex that i drew earlier the enzyme has a shape the
37:50
protein has a shape they come together by coupling and that changes what how they can interact with the rest of the world and we can
37:56
talk about those shapes of both the enzyme and the protein and the interconnection and the
38:01
interaction with the world all with polynomials and so that's lovely okay so this is the math that i sketched
38:08
verbally earlier uh spelled out in a little more detail not very much because i'm mostly
38:14
interested in storytelling today but as i said a general polynomial looks like a sum of these kind of terms
38:20
a sum of effectively these representable copri sheets um and so i'm going to call a general
38:27
polynomial p is going to be indexed by this p of 1 thing which we could talk about why it's
38:33
p of 1 later but just bear with me on that and i'm going to call each
38:38
part of this polynomial each factor of this sum p square brackets i so for instance in
38:44
this example above p of 1 is going to be a plus b plus c because as i said it's got a times y of
38:49
x b times y y and so we just add up these coefficient types and so if i is in a
38:57
then we have x as the uh the kind of total the fact of the total
39:03
space here and this gives us a bundle it gives us a bundle over this p of one type okay so that's
39:10
why there's one reason why i also have bundles earlier so i like to think of these polynomials as
39:15
phenotypes the base type is the type or the set of configurations or the morphology that the system can have
39:22
and then each of these p of i's is the type of imminent signals that the the system can
39:30
receive for instance you know think of a hedgehog it's going around the world uh it receives you know wind and
39:38
light and heat on its surface and it makes judgments about the world on the basis of that and then you know
39:45
it might get scared so it curls up into a ball which means that no longer is its underbelly kind of exposed to the world
39:51
and so the type of signals that it's receiving changes because it's changed its shape and that's the same with all sorts of
39:57
systems they have shapes and the things and the things that they can do or the
40:02
sensations that they can receive depends on the shape that they choose i like also to think that these
40:08
things formalize markup blankets because everything comes in through this sensoria and it the system
40:13
acts by changing its shape it just acts by changing its its blanket its phenotype
40:19
its morphology okay and then as i've said the morphisms of polynomials model
40:25
these interactions just like on the left and i'm not going to go into this very
40:30
much but i'd like to use it later so we can also assign positions in the world to these
40:35
polynomials by thinking of the polynomials themselves as depending on positions of some other polynomial using kind of
40:41
dependent types and then the kind of base polynomial of this of this dependence would represent the shape of the world
40:48
um but yes as i say there's that's a bit much to get into right now okay so we can start to animate these
40:55
polynomial systems these shapes now um because we can index the category i described earlier
Internal Models: Polynomially-Indexed Statistical Games
41:02
of statistical games by polynomials it's like a slice construction but we
41:08
effectively slice over the total space of each polynomial and that says that and that gives us a
41:14
category over each polynomial of of systems of systems predicting
41:19
this of like sensoriums the sense data that they those systems can receive in each
41:25
configuration and they might have a belief about their particular their particular configuration right now
41:32
and the sensations they can receive in that configuration and the cat we have a category of these things because we
41:38
might have lots of different kinds of internal model and we want to think about the morphisms between them and things like that so we get this index category
41:45
of statistical games over polynomials it's a vibration a vibration is just a categorified
41:51
bundle and we can think of what happens if we sample from the predicted configurations
41:58
and that effectively says something like we get something a bit like action because it says what configuration should i choose right now
42:05
and because of the index because the index category is a function on polynomials we also get
42:12
a description of what happens given a polynomial morphism which is effectively like a description of the generative model of
42:18
a composite system or a multi-agent system in terms of the component systems models and so you can think of something like
42:24
getting a model of the beliefs of something like a corporation giving the beliefs of the system the parts of the system the people that work
42:31
within it um okay but these things they still don't do anything they're just abstract
42:37
statistical games we want to sort of breathe life into them so i have this thing i stole this word
Active Inference Doctrines
42:45
doctrine from david jazz i like it so thank you david um i have this thing called an active inference
42:50
doctrine which is like a recipe for turning polynomially indexed statistical games into dynamical systems
42:57
and these give us index functions and it says given some statistical game
43:02
i can do some dynamical process to optimize my performance at playing that game so
43:08
in something like the free energy literature you get various recipes for doing this approximate inference
43:14
thing which give rise to processes of perception and action processes by
43:19
which systems choose their configurations and make predictions about the sensations that
43:25
they receive from their environment so these resulting dynamic systems do this perception and action and then they can in doing
43:32
those two processes they can bring their beliefs into alignment with reality whatever that means and
43:38
improve their chances of survival or their abilities to find abstractions or their fulfillment or whatever
43:44
and so the question now is okay what what is that whatever what what drives these systems
43:51
um and i like i'm gonna think of systems with this this driving process this uh elan vital as a kind of
Systems with Volition (2/2)
43:58
as giving systems volition okay so recall that the system's performance of playing one
44:05
of these games is contextual it depends on the prior beliefs and those prior beliefs include the
44:10
model structure the particular choice of statistical gains the particular choice of lens and on the
44:16
environment and so the to improve the system's performance of playing a game the system can do four things which are
44:22
basically two things the first is update the beliefs that's perception the second is update the model structure
44:28
which is a kind of perception we could figure this latent space of these models as roughly like the space
44:34
of possible external states the system can also change its shape which is like action or it could couple
44:40
with part of the world and change that shape which is like another kind of action i could go along to you and poke you and
44:45
you might do something okay and so by equipping the system with strong like internal beliefs like beliefs with
44:52
low variance around a particular state we can give it preferences for those states and then the system will attempt to
44:58
achieve those states and in doing so display something like volition okay so
45:04
we could sketch a couple of examples of this starting back with the biological systems that i was talking about earlier
45:10
a nice simple one is homeostasis so suppose that the system sensorium
45:15
includes a heap parameter like the ambient temperature but it needs to maintain a particular range
45:22
for its survival and then suppose that by adjusting its configuration the system can move around to sample
45:28
this parameter and that the prior given to this system encodes a high precision or low variance
45:35
distribution centered on this acceptable range of the parameter and so then
45:40
if it's playing a free energy game and it's given a dynamical system which does minimizing free energy the system
45:47
will attempt to configure itself in such a way that it remains within this acceptable parameter range and we can
45:53
think of that as like homeostasis i don't have time or space to give you all the details but it works something like that
46:01
and we can you know if we think we've got multiple of these systems that's doing this homeostasis thing or
46:07
obtaining some uh desired parameter configuration we could think of morphogenesis and now
46:15
let's think of this parameter as like some signaling molecule in the environment the map of polynomials encodes the
46:21
pattern of signaling molecules that is received by each system given the configuration of the rest of the
46:27
systems and suppose that the priors of these systems encode target local configurations like the
46:33
preferences of what's near me around me and then doing each of these things doing free energy minimization induces
46:40
the systems as a whole to arrange themselves to obtain some like global target pattern and we can
46:46
think of this as forming a particular composite morphology morphogenesis we can also use this
46:52
language to talk about the the world inside the mind of the system
The Internal Universe of an Active System
46:58
um we can use this to map that model like navigation of this this world arbit these words can be like
47:05
arbitrary spaces so we can attach if we attach these polynomials to positions in some world
47:12
um that world could be anything it could be the topos that i started talking about earlier
47:18
and then and there's no need to restrict the type of thing that the the type of object that the
47:25
the latent space of the internal model is and it it too might be structured like atomos
47:30
and we could think of the parameters of this model as encoding the structure of the topos
47:36
that the system expects to be out in the world the context or the shape of the world and then
47:42
updating the model parameters means moving around in this base topos means learning
47:48
what maps to where in the world given the context and then the state representation that
47:56
the system has in mind says where am i in this abstract or this
48:01
you know relatively abstract or more or less after it's real i don't care there's space
48:07
and action corresponds to moving around the space following a morphism in the top horse
48:13
and then you could think of there being some sense data i don't know what that is and it would vary corresponding to this action in a nice vibrational way
48:20
and putting a prior on a particular location a particular object in this topos would
48:26
could induce the system to reach that location learning the structure on the way and in particular if i'm trying to you
48:32
know if i'm trying to do some kind of mathematical proof i have a particular place i want to end
48:37
up with loosely defined and i'm trying to navigate myself towards it
48:42
and this then says to me okay well navigating a space is really just like finding a mathematical proof and so
48:48
abstractly there's no reason we should think of them as much different and i like to think this points towards something like a well-typed theory of
48:55
cognition where actions correspond to like applying morphisms and we can change the
49:00
structure of the space by applying morphisms and there are some nice universal morphisms we can we can use
49:06
and we can you know talk about what happens if i make an action using the internal harm or of the
49:13
cartesian closed structure that's loads of stuff to talk about and in particular we could do things like
49:19
use the internal logical language to put logical constraints on the target state
49:24
to say you know these type these states these locations in the top us they're dangerous don't go there or more complicated
49:33
propositions that involve you know dependence or implication or quantifiers it doesn't
49:39
matter we can use this internal language to say prefer these these propositions to hold
49:45
and not others but for the precise details of how to do all that is kind of left to figure out but i still think that i mean
49:51
it's a direction to me that seems promising so i will wrap up at this point it seems increasingly natural to me to
Concluding Remarks (1/2)
49:58
think of the world inside my own head like a topos structure learning finding abstractions
50:04
becomes becomes kind of like a logical context learning my brain seems to assign beliefs to
50:10
propositions it acts like a kind of classifying object um
50:15
and we could represent beliefs about processes using the internal cartesian closed structure and we could
50:21
do things like ask how do different systems internal universes compare do they have
50:27
similar beliefs about the context do we have consensus if not what are the obstructions i i'm
50:34
really keen to connect up with the stuff that david was talking about last week in this respect and then to me
50:40
finding the right abstraction seems to me something like finding good explanations in our world more often than not they do
50:48
seem to be compositional and it's reusing them reusable poetically speaking that means something
50:54
like finding compelling stories and notice that good compelling stories are the ones that hang around for the
51:00
last a long time those are both ancient stories like um epics
51:06
from long ago as well as you know mathematical stories like the right descriptions of things like spaces um
51:14
but i do want to emphasize that in a complex world notice that all these statistical games
51:19
the performance really depended on this context information and again logical statements that you can make in
51:24
a top cost really depends on the context so considering systems in isolation is not helpful we should always ask what is
51:31
the context what things are connected to me okay and of course you know there's loads left to do among other questions
51:39
to what extent does this process by which we or our brains find abstractions the process that i've
51:44
begun to sketch today agree with the kind of mathematical descriptions of things like
51:50
abstraction in terms of concepts like like boxing or hierarchical planners and other accounts it what's missing how do
51:57
we relate them i don't know how do they relate to causal or temporal
52:02
inference we see explicit signatures of the kind of cognition that i'm pointing out
52:07
in the brain itself its compositionality the kinds of representations that are required
52:13
can we how if we can do we use the internal language of this topos that is
52:18
this internal universe in my head to encode constraints on the on the
52:23
behaviors of active systems possibly like ais but also including corporations
52:29
or you know or you know if we're interested in biological design it's a similar thing
52:35
and then how can we compare systems internal universes how do i know that you know the stuff that you see or
52:43
your explanations are compelling uh for you how do i know that what you find compelling is is the same
52:50
as or related to what i find compelling and how do i know that our stories really kind of resonate i you know
52:56
i think we we've got mathematical tools to answer these questions really it just amounts to sort of
53:03
applying them although of course it's easier said than done but that's all i'm gonna say today so um
53:09
thanks i should have written thanks there but i didn't um that's my talk
